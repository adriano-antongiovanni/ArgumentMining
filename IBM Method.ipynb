{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc44b84",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c6a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4a87f",
   "metadata": {},
   "source": [
    "# Dataframe load and Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7d605",
   "metadata": {},
   "source": [
    "In this settings, I transform the csv file dataset from IBM Project Debater into an pandas dataframe df. Different slices of this pandas dataframe will be used in the different experiments in this analysis.\n",
    "\n",
    "Also, in this section I define some global variables, such as api_Key, that will be necessary to run some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80534b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc64911",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This API key is given by the early access program of the IBM Debater, for academic use only, and it is requested \n",
    "via e-mail to the IBM Debater Team. It is important to notice that, in order to make the IBM Debater API work,\n",
    "you need to clone the IBM Debater API repository.\n",
    "'''\n",
    "\n",
    "api_key = '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3757922",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['bert-base-uncased', 'bert-large-uncased', 'bert-base-cased-finetuned-mrpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb659d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f72dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b827d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making adjustments for model comprehensions\n",
    "df = df.replace('PRO', int(1))\n",
    "df = df.replace('CON', int(0))\n",
    "df= df.replace(-1, int(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f2485",
   "metadata": {},
   "source": [
    "# Data Frame Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864105eb",
   "metadata": {},
   "source": [
    "In this section, I select the important parts of the pandas dataframe, which are: the topic and claim text (str), the topic and claim sentiment classification (int, [-1,1]), the claim and target relation classification (int, [-1,1]), the stance (str, ['PRO', 'CON']) and the split (str, ['train','test']).    \n",
    "\n",
    "The texts will be used in the evaluated models, the classifications will be used to reproduce the formula of the refered article, the stance will be used to evaluate those models and the separation will be used to separate the inputs of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be963c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the orifginal data frame into four dataframes\n",
    "df_topicSentiment = df[['topicText', 'topicSentiment', 'split']] \n",
    "df_claimSentiment = df[['claims.claimOriginalText', 'claims.claimSentiment', 'split']] \n",
    "df_targetsRelation = df[['topicText', 'claims.claimOriginalText', 'claims.targetsRelation', 'split']]\n",
    "df_resposta = df[['claims.stance', 'split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4181854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renbaming colums \n",
    "df_topicSentiment.set_axis(['text', 'labels', 'split'], axis='columns', inplace=True)\n",
    "df_claimSentiment.set_axis(['text', 'labels', 'split'], axis='columns', inplace=True)\n",
    "df_targetsRelation.set_axis(['textTopic', 'textClaim', 'labels', 'split'], axis='columns', inplace=True)\n",
    "df_resposta.set_axis(['resuls', 'split'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd249408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANTONG~1\\AppData\\Local\\Temp/ipykernel_3528/2194246794.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_targetsRelation['text'] = df_targetsRelation['textTopic'] + ' [SEP] [CLS] ' + df_targetsRelation['textClaim']\n"
     ]
    }
   ],
   "source": [
    "#Adjusting df_targestRelation to have an single entry of two sentences (topic and claim) with an separation encoding\n",
    "df_targetsRelation['text'] = df_targetsRelation['textTopic'] + ' [SEP] [CLS] ' + df_targetsRelation['textClaim']\n",
    "#df_targetsRelation['text'] = df_targetsRelation.apply(lambda row: row.textTopic + ' </s> ' + row.textClaim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef91eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-IBM, 2-Random: 2\n",
      "Are You going to train using the refered article's formula [type 1] or with just an topic and claim input [type 2]? 1\n",
      "Wich tokenizer do you want to use? bert-base-uncased [type 1], bert-large-uncased [type 2] or bert-base-cased-finetuned-mrpc [type 3]? 2\n"
     ]
    }
   ],
   "source": [
    "split_type = int(input(\"1-IBM, 2-Random: \"))\n",
    "input_type = int(input(\"Are You going to train using the refered article's formula [type 1] or with just an topic and claim input [type 2]? \"))\n",
    "token_choice = int(input('Wich tokenizer do you want to use? bert-base-uncased [type 1], bert-large-uncased [type 2] or bert-base-cased-finetuned-mrpc [type 3]? '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc29d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if split_type == 1:\n",
    "    df_topicSentiment_train = df_topicSentiment.loc[df['split'] == 'train']\n",
    "    df_claimSentiment_train = df_claimSentiment.loc[df['split'] == 'train']\n",
    "    df_targetsRelation_train = df_targetsRelation.loc[df['split'] == 'train']\n",
    "    df_resposta_train = df_resposta.loc[df['split'] == 'train']\n",
    "\n",
    "    df_topicSentiment_val = df_topicSentiment.loc[df['split'] == 'test']\n",
    "    df_claimSentiment_val = df_claimSentiment.loc[df['split'] == 'test']\n",
    "    df_targetsRelation_val = df_targetsRelation.loc[df['split'] == 'test']\n",
    "    df_resposta_val = df_resposta.loc[df['split'] == 'test']\n",
    "    \n",
    "    #Making the the entry of the models\n",
    "    text = [df_topicSentiment_train['text'].values, df_claimSentiment_train['text'].values, df_targetsRelation_train['text'].values,\n",
    "       df_topicSentiment_val['text'].values, df_claimSentiment_val['text'].values, df_targetsRelation_val['text'].values]\n",
    "    labels = [df_topicSentiment_train['labels'].values, df_claimSentiment_train['labels'].values, df_targetsRelation_train['labels'].values,\n",
    "         df_topicSentiment_val['labels'].values, df_claimSentiment_val['labels'].values, df_targetsRelation_val['labels'].values,\n",
    "         df_resposta_val['resuls'].values]\n",
    "\n",
    "if split_type == 2:\n",
    "    \n",
    "    #Making the the entry of the models\n",
    "    text = [df_topicSentiment['text'].values, df_claimSentiment['text'].values, df_targetsRelation['text'].values]\n",
    "    labels = [df_topicSentiment['labels'].values, df_claimSentiment['labels'].values, df_targetsRelation['labels'].values,\n",
    "             df_resposta['resuls'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055d204",
   "metadata": {},
   "source": [
    "# Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccdf6e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for tokening\n",
    "\n",
    "'''\n",
    "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "'''\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "        return tokenizer.encode_plus(\n",
    "                            input_text\n",
    "                            ,add_special_tokens = True\n",
    "                            ,max_length = 32\n",
    "                            ,pad_to_max_length = True\n",
    "                            ,return_attention_mask = True\n",
    "                            ,return_tensors = 'pt'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "266f81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for model evaluation\n",
    "\n",
    "def b_tp(preds, labels):\n",
    "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
    "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fp(preds, labels):\n",
    "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
    "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_tn(preds, labels):\n",
    "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
    "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fn(preds, labels):\n",
    "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
    "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_metrics(preds, labels):\n",
    "  '''\n",
    "  Returns the following metrics:\n",
    "    - accuracy    = (TP + TN) / N\n",
    "    - precision   = TP / (TP + FP)\n",
    "    - recall      = TP / (TP + FN)\n",
    "    - specificity = TN / (TN + FP)\n",
    "  '''\n",
    "  preds = np.argmax(preds, axis = 1).flatten()\n",
    "  labels = labels.flatten()\n",
    "  tp = b_tp(preds, labels)\n",
    "  tn = b_tn(preds, labels)\n",
    "  fp = b_fp(preds, labels)\n",
    "  fn = b_fn(preds, labels)\n",
    "  b_accuracy = (tp + tn) / len(labels)\n",
    "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
    "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
    "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
    "  return b_accuracy, b_precision, b_recall, b_specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8a933",
   "metadata": {},
   "source": [
    "# Preparing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45853792",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokens[token_choice-1]\n",
    "tokenizer = BertTokenizer.from_pretrained(token, do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0019c588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if split_type == 1:\n",
    "    \n",
    "    #TopicSentiment Train\n",
    "    token_id_topic_train = []\n",
    "    attention_masks_topic_train = []\n",
    "\n",
    "    for sample in text[0]:\n",
    "      encoding_dict_topic_train = preprocessing(sample, tokenizer)\n",
    "      token_id_topic_train.append(encoding_dict_topic_train['input_ids']) \n",
    "      attention_masks_topic_train.append(encoding_dict_topic_train['attention_mask'])\n",
    "\n",
    "    token_id_topic_train = torch.cat(token_id_topic_train, dim = 0)\n",
    "    attention_masks_topic_train = torch.cat(attention_masks_topic_train, dim = 0)\n",
    "    labels_topic_train = torch.tensor(labels[0])\n",
    "    labels_topic_train =  torch.nan_to_num(labels_topic_train)\n",
    "    labels_topic_train = labels_topic_train.type(torch.int64)\n",
    "\n",
    "    #TopicSentiment Val\n",
    "    token_id_topic_val = []\n",
    "    attention_masks_topic_val = []\n",
    "\n",
    "    for sample in text[3]:\n",
    "      encoding_dict_topic_val = preprocessing(sample, tokenizer)\n",
    "      token_id_topic_val.append(encoding_dict_topic_val['input_ids']) \n",
    "      attention_masks_topic_val.append(encoding_dict_topic_val['attention_mask'])\n",
    "\n",
    "    token_id_topic_val = torch.cat(token_id_topic_val, dim = 0)\n",
    "    attention_masks_topic_val = torch.cat(attention_masks_topic_val, dim = 0)\n",
    "    labels_topic_val = torch.tensor(labels[3])\n",
    "    labels_topic_val =  torch.nan_to_num(labels_topic_val)\n",
    "    labels_topic_val = labels_topic_val.type(torch.int64)\n",
    "\n",
    "    #ClaimSentiment Train\n",
    "    token_id_claim_train = []\n",
    "    attention_masks_claim_train = []\n",
    "\n",
    "    for sample in text[1]:\n",
    "      encoding_dict_claim_train = preprocessing(sample, tokenizer)\n",
    "      token_id_claim_train.append(encoding_dict_claim_train['input_ids']) \n",
    "      attention_masks_claim_train.append(encoding_dict_claim_train['attention_mask'])\n",
    "\n",
    "    token_id_claim_train = torch.cat(token_id_claim_train, dim = 0)\n",
    "    attention_masks_claim_train = torch.cat(attention_masks_claim_train, dim = 0)\n",
    "    labels_claim_train = torch.tensor(labels[1])\n",
    "    labels_claim_train =  torch.nan_to_num(labels_claim_train)\n",
    "    labels_claim_train = labels_claim_train.type(torch.int64)\n",
    "\n",
    "    #ClaimSentiment Val\n",
    "    token_id_claim_val = []\n",
    "    attention_masks_claim_val = []\n",
    "\n",
    "    for sample in text[4]:\n",
    "      encoding_dict_claim_val = preprocessing(sample, tokenizer)\n",
    "      token_id_claim_val.append(encoding_dict_claim_val['input_ids']) \n",
    "      attention_masks_claim_val.append(encoding_dict_claim_val['attention_mask'])\n",
    "\n",
    "    token_id_claim_val = torch.cat(token_id_claim_val, dim = 0)\n",
    "    attention_masks_claim_val = torch.cat(attention_masks_claim_val, dim = 0)\n",
    "    labels_claim_val = torch.tensor(labels[4])\n",
    "    labels_claim_val =  torch.nan_to_num(labels_claim_val)\n",
    "    labels_claim_val = labels_claim_val.type(torch.int64)\n",
    "\n",
    "    #RelationSentiment Train\n",
    "    token_id_relation_train = []\n",
    "    attention_masks_relation_train = []\n",
    "\n",
    "    for sample in text[2]:\n",
    "      encoding_dict_relation_train = preprocessing(sample, tokenizer)\n",
    "      token_id_relation_train.append(encoding_dict_relation_train['input_ids']) \n",
    "      attention_masks_relation_train.append(encoding_dict_relation_train['attention_mask'])\n",
    "\n",
    "    token_id_relation_train = torch.cat(token_id_relation_train, dim = 0)\n",
    "    attention_masks_relation_train = torch.cat(attention_masks_relation_train, dim = 0)\n",
    "    labels_relation_train = torch.tensor(labels[2])\n",
    "    labels_relation_train =  torch.nan_to_num(labels_relation_train)\n",
    "    labels_relation_train = labels_relation_train.type(torch.int64)\n",
    "\n",
    "    #RelationSentiment Val_1\n",
    "    token_id_relation_val = []\n",
    "    attention_masks_relation_val = []\n",
    "\n",
    "    for sample in text[5]:\n",
    "      encoding_dict_relation_val = preprocessing(sample, tokenizer)\n",
    "      token_id_relation_val.append(encoding_dict_relation_val['input_ids']) \n",
    "      attention_masks_relation_val.append(encoding_dict_relation_val['attention_mask'])\n",
    "\n",
    "    token_id_relation_val = torch.cat(token_id_relation_val, dim = 0)\n",
    "    attention_masks_relation_val = torch.cat(attention_masks_relation_val, dim = 0)\n",
    "    labels_relation_val = torch.tensor(labels[5])\n",
    "    labels_relation_val =  torch.nan_to_num(labels_relation_val)\n",
    "    labels_relation_val = labels_relation_val.type(torch.int64)\n",
    "\n",
    "    #RelationSentiment Val_2\n",
    "    token_id_relation_val_general = []\n",
    "    attention_masks_relation_val_general = []\n",
    "\n",
    "    for sample in text[5]:\n",
    "      encoding_dict_relation_val_general = preprocessing(sample, tokenizer)\n",
    "      token_id_relation_val_general.append(encoding_dict_relation_val_general['input_ids']) \n",
    "      attention_masks_relation_val_general.append(encoding_dict_relation_val_general['attention_mask'])\n",
    "\n",
    "    token_id_relation_val_general = torch.cat(token_id_relation_val_general, dim = 0)\n",
    "    attention_masks_relation_val_general = torch.cat(attention_masks_relation_val_general, dim = 0)\n",
    "    labels_relation_val_general = torch.tensor(labels[6])\n",
    "    labels_relation_val_general =  torch.nan_to_num(labels_relation_val_general)\n",
    "    labels_relation_val_general = labels_relation_val_general.type(torch.int64)\n",
    "    \n",
    "if split_type == 2:\n",
    "    \n",
    "    #Topic\n",
    "    token_id_topic = []\n",
    "    attention_masks_topic = []\n",
    "\n",
    "    for sample in text[0]:\n",
    "      encoding_dict_topic = preprocessing(sample, tokenizer)\n",
    "      token_id_topic.append(encoding_dict_topic['input_ids']) \n",
    "      attention_masks_topic.append(encoding_dict_topic['attention_mask'])\n",
    "\n",
    "    token_id_topic = torch.cat(token_id_topic, dim = 0)\n",
    "    attention_masks_topic = torch.cat(attention_masks_topic, dim = 0)\n",
    "    labels_topic = torch.tensor(labels[0])\n",
    "    labels_topic =  torch.nan_to_num(labels_topic)\n",
    "    labels_topic = labels_topic.type(torch.int64)\n",
    "    \n",
    "    #Claim\n",
    "    token_id_claim = []\n",
    "    attention_masks_claim = []\n",
    "    \n",
    "    for sample in text[1]:\n",
    "      encoding_dict_claim = preprocessing(sample, tokenizer)\n",
    "      token_id_claim.append(encoding_dict_claim['input_ids']) \n",
    "      attention_masks_claim.append(encoding_dict_claim['attention_mask'])\n",
    "\n",
    "    token_id_claim = torch.cat(token_id_claim, dim = 0)\n",
    "    attention_masks_claim = torch.cat(attention_masks_claim, dim = 0)\n",
    "    labels_claim = torch.tensor(labels[1])\n",
    "    labels_claim =  torch.nan_to_num(labels_claim)\n",
    "    labels_claim = labels_claim.type(torch.int64)\n",
    "    \n",
    "    #Relation\n",
    "    token_id_relation = []\n",
    "    attention_masks_relation = []\n",
    "    \n",
    "    for sample in text[2]:\n",
    "      encoding_dict_relation = preprocessing(sample, tokenizer)\n",
    "      token_id_relation.append(encoding_dict_relation['input_ids']) \n",
    "      attention_masks_relation.append(encoding_dict_relation['attention_mask'])\n",
    "\n",
    "    token_id_relation = torch.cat(token_id_relation, dim = 0)\n",
    "    attention_masks_relation = torch.cat(attention_masks_relation, dim = 0)\n",
    "    labels_relation = torch.tensor(labels[2])\n",
    "    labels_relation =  torch.nan_to_num(labels_relation)\n",
    "    labels_relation = labels_relation.type(torch.int64)\n",
    "    \n",
    "    token_id_relation_pure = []\n",
    "    attention_masks_relation_pure = []\n",
    "    \n",
    "    for sample in text[2]:\n",
    "      encoding_dict_relation_pure = preprocessing(sample, tokenizer)\n",
    "      token_id_relation_pure.append(encoding_dict_relation_pure['input_ids']) \n",
    "      attention_masks_relation_pure.append(encoding_dict_relation_pure['attention_mask'])\n",
    "\n",
    "    token_id_relation_pure = torch.cat(token_id_relation_pure, dim = 0)\n",
    "    attention_masks_relation_pure = torch.cat(attention_masks_relation_pure, dim = 0)\n",
    "    labels_relation_pure = torch.tensor(labels[3])\n",
    "    labels_relation_pure =  torch.nan_to_num(labels_relation_pure)\n",
    "    labels_relation_pure = labels_relation_pure.type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f45fc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if split_type == 1: \n",
    "    if input_type == 1:\n",
    "        # Train and validation sets for claimclaim\n",
    "        train_set_claimSentiment = TensorDataset(token_id_claim_train, \n",
    "                                  attention_masks_claim_train, \n",
    "                                  labels_claim_train)\n",
    "\n",
    "        val_set_claimSentiment = TensorDataset(token_id_claim_val, \n",
    "                                  attention_masks_claim_val, \n",
    "                                  labels_claim_val)\n",
    "\n",
    "        # Train and validation sets for topic\n",
    "        train_set_topicSentiment = TensorDataset(token_id_topic_train, \n",
    "                                  attention_masks_topic_train, \n",
    "                                  labels_topic_train)\n",
    "\n",
    "        val_set_topicSentiment = TensorDataset(token_id_topic_val, \n",
    "                                  attention_masks_topic_val, \n",
    "                                  labels_topic_val)\n",
    "\n",
    "        # Train and validation sets for target relation\n",
    "        train_set_targetRelation = TensorDataset(token_id_relation_train, \n",
    "                                  attention_masks_relation_train, \n",
    "                                  labels_relation_train)\n",
    "\n",
    "        val_set_targetRelation = TensorDataset(token_id_relation_val, \n",
    "                                  attention_masks_relation_val, \n",
    "                                  labels_relation_val)\n",
    "\n",
    "    if input_type == 2:\n",
    "\n",
    "        train_set = TensorDataset(token_id_relation_train_general, \n",
    "                                  attention_masks_relation_train_general, \n",
    "                                  labels_relation_train_general)\n",
    "\n",
    "        val_set = TensorDataset(token_id_relation_val_general, \n",
    "                                  attention_masks_relation_val_general, \n",
    "                                  labels_relation_val_general)\n",
    "        \n",
    "if split_type == 2:\n",
    "    \n",
    "    val_ratio = 0.2\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels_topic)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True)\n",
    "    \n",
    "    if input_type == 1:\n",
    "        # Train and validation sets for claim\n",
    "        train_set_claimSentiment = TensorDataset(token_id_claim[train_idx], \n",
    "                                  attention_masks_claim[train_idx], \n",
    "                                  labels_claim[train_idx])\n",
    "\n",
    "        val_set_claimSentiment = TensorDataset(token_id_claim[val_idx], \n",
    "                                  attention_masks_claim[val_idx], \n",
    "                                  labels_claim[val_idx])\n",
    "\n",
    "        # Train and validation sets for topic\n",
    "        train_set_topicSentiment = TensorDataset(token_id_topic[train_idx], \n",
    "                                  attention_masks_topic[train_idx], \n",
    "                                  labels_topic[train_idx])\n",
    "\n",
    "        val_set_topicSentiment = TensorDataset(token_id_topic[val_idx], \n",
    "                                  attention_masks_topic[val_idx], \n",
    "                                  labels_topic[val_idx])\n",
    "\n",
    "        # Train and validation sets for target relation\n",
    "        train_set_targetRelation = TensorDataset(token_id_relation[train_idx], \n",
    "                                  attention_masks_relation[train_idx], \n",
    "                                  labels_relation[train_idx])\n",
    "\n",
    "        val_set_targetRelation = TensorDataset(token_id_relation[val_idx], \n",
    "                                  attention_masks_relation[val_idx], \n",
    "                                  labels_relation[val_idx])\n",
    "\n",
    "    if input_type == 2:\n",
    "\n",
    "        train_set = TensorDataset(token_id_relation_pure[train_idx], \n",
    "                                  attention_masks_relation_pure[train_idx], \n",
    "                                  labels_relation_pure[train_idx])\n",
    "\n",
    "        val_set = TensorDataset(token_id_relation_pure[val_idx], \n",
    "                                  attention_masks_relation_pure[val_idx], \n",
    "                                  labels_relation_pure[val_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f60c5",
   "metadata": {},
   "source": [
    "# Preparing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2e108ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(token,num_labels = 2,output_attentions = False,\n",
    "                                                          output_hidden_states = False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr = 5e-5, # 5e-5, 3e-5, 2e-5\n",
    "                              eps = 1e-08\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ce87c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce151d0",
   "metadata": {},
   "source": [
    "# Model Runing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39cec9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c324060",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = [[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a599ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wich step are you in: topic[1], claim[2] or relation[3]? 3\n"
     ]
    }
   ],
   "source": [
    "option = int(input('Wich step are you in: topic[1], claim[2] or relation[3]? '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea0b8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if option-1 == 0:\n",
    "    train_set = train_set_claimSentiment\n",
    "    val_set = val_set_claimSentiment\n",
    "\n",
    "elif option-1 == 1:\n",
    "    train_set = train_set_topicSentiment\n",
    "    val_set = val_set_topicSentiment\n",
    "\n",
    "elif option-1 == 2:\n",
    "    train_set = train_set_targetRelation\n",
    "    val_set = val_set_targetRelation\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "                train_set,\n",
    "                sampler = RandomSampler(train_set),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "                val_set,\n",
    "                sampler = SequentialSampler(val_set),\n",
    "                batch_size = batch_size\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9359d4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██████████████████▎                                                      | 1/4 [20:43<1:02:11, 1243.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.5143\n",
      "\t - Validation Accuracy: 0.8021\n",
      "\t - Validation Precision: 0.8021\n",
      "\t - Validation Recall: 1.0000\n",
      "\t - Validation Specificity: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████████████████████████▌                                     | 2/4 [40:35<40:26, 1213.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.5036\n",
      "\t - Validation Accuracy: 0.8021\n",
      "\t - Validation Precision: 0.8021\n",
      "\t - Validation Recall: 1.0000\n",
      "\t - Validation Specificity: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|██████████████████████████████████████████████████████▊                  | 3/4 [1:01:34<20:34, 1234.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.5062\n",
      "\t - Validation Accuracy: 0.8021\n",
      "\t - Validation Precision: 0.8021\n",
      "\t - Validation Recall: 1.0000\n",
      "\t - Validation Specificity: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████████████████████████████████████████████████| 4/4 [1:21:04<00:00, 1216.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.5079\n",
      "\t - Validation Accuracy: 0.8021\n",
      "\t - Validation Precision: 0.8021\n",
      "\t - Validation Recall: 1.0000\n",
      "\t - Validation Specificity: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if input_type == 1:\n",
    "    for k in range(0,1):\n",
    "\n",
    "        for _ in trange(epochs, desc = 'Epoch'):\n",
    "\n",
    "            # ========== Training ==========\n",
    "\n",
    "            # Set model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # Tracking variables\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "                optimizer.zero_grad()\n",
    "                # Forward pass\n",
    "                train_output = model(b_input_ids, \n",
    "                                     token_type_ids = None, \n",
    "                                     attention_mask = b_input_mask, \n",
    "                                     labels = b_labels)\n",
    "                # Backward pass\n",
    "                train_output.loss.backward()\n",
    "                optimizer.step()\n",
    "                # Update tracking variables\n",
    "                tr_loss += train_output.loss.item()\n",
    "                nb_tr_examples += b_input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "\n",
    "           # ========== Validation ==========\n",
    "\n",
    "            # Set model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Tracking variables \n",
    "            val_accuracy = []\n",
    "            val_precision = []\n",
    "            val_recall = []\n",
    "            val_specificity = []\n",
    "\n",
    "            for batch in validation_dataloader:\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "                with torch.no_grad():\n",
    "                  # Forward pass\n",
    "                  eval_output = model(b_input_ids, \n",
    "                                      token_type_ids = None, \n",
    "                                      attention_mask = b_input_mask)\n",
    "\n",
    "                logits = eval_output.logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                # Calculate validation metrics\n",
    "                b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
    "                val_accuracy.append(b_accuracy)\n",
    "                # Update precision only when (tp + fp) !=0; ignore nan\n",
    "                if b_precision != 'nan': val_precision.append(b_precision)\n",
    "                # Update recall only when (tp + fn) !=0; ignore nan\n",
    "                if b_recall != 'nan': val_recall.append(b_recall)\n",
    "                # Update specificity only when (tn + fp) !=0; ignore nan\n",
    "                if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
    "\n",
    "\n",
    "            print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "            print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "            print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "            print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "            print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808b882",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88d6822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_type == 1:\n",
    "    train_idx = np.array(df.index[df['split'] == 'train'].tolist())\n",
    "    val_idx = np.array(df.index[df['split'] == 'train'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f344eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecionar qual base usar\n",
    "if option  == 3 or option == 0:\n",
    "    frases = df_targetsRelation['text'][val_idx].values.tolist()\n",
    "elif option  == 1:\n",
    "    frases = df['topicText'][val_idx].values.tolist()\n",
    "elif option == 2:\n",
    "    frases = df['claims.claimCorrectedText'][val_idx].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4cbaf672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for i in frases:\n",
    "    new_sentence = i\n",
    "\n",
    "    # We need Token IDs and Attention Mask for inference on the new sentence\n",
    "    test_ids = []\n",
    "    test_attention_mask = []\n",
    "\n",
    "    # Apply the tokenizer\n",
    "    encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "    # Extract IDs and Attention Mask\n",
    "    test_ids.append(encoding['input_ids'])\n",
    "    test_attention_mask.append(encoding['attention_mask'])\n",
    "    test_ids = torch.cat(test_ids, dim = 0)\n",
    "    test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "    # Forward pass, calculate logit predictions\n",
    "    with torch.no_grad():\n",
    "      output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "\n",
    "    prediction = 1 if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 0\n",
    "    \n",
    "    prediction_list.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f06b37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if option == 3 or option== 0:\n",
    "    predictions_list[2] = prediction_list\n",
    "elif option == 1:\n",
    "    predictions_list[0] = prediction_list\n",
    "elif option == 2:\n",
    "    predictions_list[1] = prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af356d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6036960985626283\n",
      "Precision:  0.6036960985626283\n",
      "Recall:  1.0\n",
      "Specificity:  0.0\n"
     ]
    }
   ],
   "source": [
    "if input_type== 2:\n",
    "    print('Accuracy: ', accuracy_score(df['claims.stance'][val_idx], predictions_list[2]))\n",
    "    print('Precision: ', precision_score(df['claims.stance'][val_idx], predictions_list[2]))\n",
    "    print('Recall: ', recall_score(df['claims.stance'][val_idx], predictions_list[2]))\n",
    "    print('Specificity: ',recall_score(df['claims.stance'][val_idx], predictions_list[2], pos_label = 0))\n",
    "\n",
    "if (input_type == 1 and option == 1):\n",
    "    print('Accuracy: ', accuracy_score(df['claims.stance'][val_idx], predictions_list[0]))\n",
    "    print('Precision: ', precision_score(df['claims.stance'][val_idx], predictions_list[0]))\n",
    "    print('Recall: ', recall_score(df['claims.stance'][val_idx], predictions_list[0]))\n",
    "    print('Specificity: ', recall_score(df['claims.stance'][val_idx], predictions_list[0], pos_label = 0))\n",
    "          \n",
    "if (input_type == 1 and option == 2):\n",
    "    print('Accuracy: ', accuracy_score(df['claims.stance'][val_idx], predictions_list[1]))\n",
    "    print('Precision: ', precision_score(df['claims.stance'][val_idx], predictions_list[1]))\n",
    "    print('Recall: ', recall_score(df['claims.stance'][val_idx], predictions_list[1]))\n",
    "    print('Specificity: ', recall_score(df['claims.stance'][val_idx], predictions_list[1], pos_label = 0))\n",
    "          \n",
    "if (input_type == 1 and option == 3):\n",
    "    print('Accuracy: ', accuracy_score(df['claims.stance'][val_idx], predictions_list[2]))\n",
    "    print('Precision: ', precision_score(df['claims.stance'][val_idx], predictions_list[2]))\n",
    "    print('Recall: ', recall_score(df['claims.stance'][val_idx], predictions_list[2]))\n",
    "    print('Specificity: ', recall_score(df['claims.stance'][val_idx], predictions_list[2], pos_label = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab936a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_menosum = df['claims.stance'][val_idx].copy()\n",
    "df= df.replace(-1, int(-1))\n",
    "\n",
    "resul_ibm_method = []\n",
    "for i in range(len(predictions_list[0])):\n",
    "    if predictions_list[0][i] == 0:\n",
    "        predictions_list[0][i] == -1\n",
    "    if predictions_list[1][i] == 0:\n",
    "        predictions_list[1][i] == -1\n",
    "    if predictions_list[2][i] == 0:\n",
    "        predictions_list[2][i] == -1\n",
    "    resul_ibm_method.append(predictions_list[0][i]*predictions_list[1][i]*predictions_list[2][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3d9c7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.39630390143737165\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "Specificity:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(resp_menosum, resul_ibm_method))\n",
    "print('Precision: ', precision_score(resp_menosum, resul_ibm_method))\n",
    "print('Recall: ', recall_score(resp_menosum, resul_ibm_method))\n",
    "print('Specificity: ',recall_score(resp_menosum, resul_ibm_method, pos_label = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa863e6",
   "metadata": {},
   "source": [
    "# Benchmark - IBM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f25ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf0657ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#df_ibm_all = df.loc[[val_idx.tolist()],['topicTarget', 'claims.claimCorrectedText', 'claims.stance']]\n",
    "#df_ibm = df_ibm_all[val_idx]\n",
    "\n",
    "df_ibm_topic = df['topicTarget'][val_idx]\n",
    "df_ibm_claim = df['claims.claimCorrectedText'][val_idx]\n",
    "df_ibm_target = df['claims.stance'][val_idx]\n",
    "\n",
    "df_ibm_topic.reset_index(drop = True, inplace = True)\n",
    "df_ibm_claim.reset_index(drop = True, inplace = True)\n",
    "\n",
    "sentence_topic_dicts = []\n",
    "for i in range(len(df_ibm_topic)):\n",
    "    dicti = {'topic': df_ibm_topic[i], 'sentence': df_ibm_claim[i]}\n",
    "    sentence_topic_dicts.append(dicti)\n",
    "    \n",
    "\n",
    "#sentence_topic_dicts = df_data.to_dict('records')\n",
    "#list_target = df_target.values.tolist()\n",
    "#list_target_corrected = []\n",
    "#for i in range(len(list_target)):\n",
    " #   list_target_corrected.append(list_target[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bf1c1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProConClient: 100%|██████████████████████████████████████████████████████████████████| 974/974 [00:25<00:00, 38.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from debater_python_api.api.debater_api import DebaterApi\n",
    "\n",
    "debater_api = DebaterApi(api_key)\n",
    "pro_con_client = debater_api.get_pro_con_client()\n",
    "\n",
    "scores = pro_con_client.run(sentence_topic_dicts)\n",
    "\n",
    "resp_ibm = []\n",
    "\n",
    "for j in range(len(sentence_topic_dicts)):\n",
    "    if scores[j] > 0:\n",
    "        resp_ibm.append(1)\n",
    "    elif scores[j] < 0:\n",
    "        resp_ibm.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daea06dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6457905544147844\n",
      "Precision:  0.7434869739478958\n",
      "Recall:  0.6309523809523809\n",
      "Specificity:  0.6683937823834197\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(df['claims.stance'][val_idx], resp_ibm))\n",
    "print('Precision: ', precision_score(df['claims.stance'][val_idx], resp_ibm))\n",
    "print('Recall: ', recall_score(df['claims.stance'][val_idx], resp_ibm))\n",
    "print('Specificity: ',recall_score(df['claims.stance'][val_idx], resp_ibm, pos_label = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae238c0",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce44b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a5b05",
   "metadata": {},
   "source": [
    "# Reference for Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f101233",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
